#!/usr/bin/env python
#todo: use a -g-l-o-b-a-l- "usage..." var (not global)
#todo: use less (no) global variables generally
#todo: docstrings
#todo: retrieve by tag
#todo: set folder name in opts
#todo: option to {in,ex}clude bookmarks by regex
from time import mktime, time
from os import popen
import urllib
import re
import sys
#could also import optparse if handle_opts()
#and getpass if no password argument passed

class urlopener(urllib.URLopener):
    '''
    Sets user-agent string to:
        "Delectus/$version ($kernel-name; $architecture; N)"
    e.g.:
        "Delectus/1.0 (Linux; i686; N)"
    '''
    try:
        arch = popen("uname -m") # system architecture
        kern = popen("uname -s") # kernel name
        version = "Delectus/0.5.2 (%s; %s; N)" %\
                  (kern.read().strip("\n"),  arch.read().strip("\n"))
    finally:
        arch.close()
        kern.close()


def api_url(username,password,count=0):
    '''
    Determines which url to use for the API request
    and returns it. If count is 0 (default) then we
    retrieve all of the users bookmarks with
    "https://user:password@api.del.icio.us/v1/posts/all",
    or else we retrieve only $count number of bookmarks
    with
    "https://user:password@api.del.icio.us/v1/posts/recent?count=$count"
    '''
    if not count:
        return "https://%s:%s@api.del.icio.us/v1/posts/all"%(
            username,password)
    return "https://%s:%s@api.del.icio.us/v1/posts/recent?count=%s"%(
        username,password,count)


def get_xml(url):
    '''
    Makes the API request and returns the raw xml recieved
    '''
    del_opener = urlopener()
    try:
        xml_req = del_opener.open(url)
        xml     = xml_req.read()
    finally:
        xml_req.close()
        return xml


def sgroup(regex,string):#surely there's a better way to do this??
    '''
    Returns only the term matched by a regex.
    '''
    return regex.search(string).group()


def parse_attr(attr_name,string):
    start= len(attr_name)+2 # id est "len(attr_nam=")"
    stop = -1
    
    return string[start:stop]


def api_time_to_epoch(time):
    #2009-06-19T17:28:55Z
    parsed = (time[0:4],  # year (2009)
              time[5:7],  # month(06)
              time[8:10], # day  (19)
              time[-9:-7],# hour (17)
              time[-6:-4],# mins (28)
              time[-3:-1],# secs (55)
              0,0,-1)
    return int(mktime(tuple(int(i) for i in parsed)))


def parse_posts(xml):
    '''
    Takes the raw xml data returned by the API request
    in `get_xml()` and sorts the data into a dictionary
    of the form:
    {
        title :
            url,
            time_posted,
            description,
            (tag,tag,tags...)
            ,
        title :
            etc...
    }
    '''
    post  = re.compile("<post .*?>\\n")
    href  = re.compile("href=\".*?\"")
    title = re.compile("description=\".*?\"")
    tags  = re.compile("tag=\".*?\"")
    desc  = re.compile("extended=\".*?\"")
    time  = re.compile("time=\".*?\"")
    
    parsed = {}

    #todo: tidy this up
    for p in post.findall(xml):
        parsed[parse_attr("description",sgroup(title,p))]=(
                              parse_attr("href", sgroup( href,p)),
           api_time_to_epoch( parse_attr("time", sgroup( time,p)) ),
                              parse_attr("extended", sgroup( desc,p)),
                       tuple( parse_attr("tag", sgroup( tags,p)).split(' ') )
        )
    return parsed


def convert_html(feed_dict):
    '''
        Iterates through the dictionary created with parse_feed(),
        and prints out a netscape-bookmark-file-1 html file using
        the values therein.
    '''
    sys.stdout.write("""\
<!DOCTYPE NETSCAPE-Bookmark-file-1>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Bookmarks</title>
<h1>Bookmarks</h1>

<dt><h3 add_date="%s" last_modified="%s">Delicious Bookmarks</h3>
""" %(int(time()),
      int(time()))
    )

    for title in iter(feed_dict):
        sys.stdout.write("""
    <dt>
        <a href="%s" last_visit="" add_date="%s" tags="%s">%s</a>
    <dd>%s\n"""%(feed_dict[title] [0], # url        
                 feed_dict[title] [1], # pubDate    
        ",".join(feed_dict[title] [3]),# tags       
                 title,                # <-         
                 feed_dict[title] [2]) # description
                    )


def convert_adr(feed_dict):
    '''
        Iterates through the dictionary created wit parse_feed(),
        and prints out an Opera ADR bookmark file, version 3, using
        the values therein.
    '''
    sys.stdout.write("""\
Opera Hotlist version 2.0
Options: encoding = utf8, version=3

#FOLDER
    NAME=Delicious Bookmarks""")

    for title in iter(feed_dict):
        sys.stdout.write("""
#URL
    NAME=%s
    URL=%s
    CREATED=%s
    DESCRIPTION=%s\n"""% (title,              # <-     
                         feed_dict[title] [0],# url    
                         feed_dict[title] [1],# pubDate
                         feed_dict[title] [2])# description
                    )


def convert_xbel(feed_dict):
    '''
        Iterates through the dictionary created wit parse_feed(),
        and prints out an XBEL file, version 1.0, as defined by
        the Python XML Special Interest Group, using the values
        therein.
    '''
    sys.stdout.write("""\
<?xml version="1.0"?>
<!DOCTYPE xbel
  PUBLIC "+//IDN python.org//DTD XML Bookmark Exchange Language 1.0//EN//XML"
         "http://www.python.org/topics/xml/dtds/xbel-1.0.dtd">
<xbel version="1.0">
    <info>This XBEL document was generated automatically using a conversion
          script for delicious.com  bookmarks.  For more information please
          visit http://github.com/AlecSchueler/Delectus/
    </info>

    <folder folded="yes">
        <title>Delicious Bookmarks</title>""")

    for title in iter(feed_dict):
        sys.stdout.write("""
            <bookmark href="%s">
                <title>%s</title>
                <info>Tags: %s</info>
                <desc>
                    %s
                </desc>
            </bookmark>""" % (feed_dict[title][0],
                              title,
                     ",".join(feed_dict[title][3]),
                              feed_dict[title][2])
                     )
    sys.stdout.write("\t</folder>\n</xbel>\n")

def convert_text(feed_dict):
    '''
    Iterates through the dictionary created with parse_feed()
    and outputs the url of each bookmark, seperated by a new-
    -line.
    '''
    for title in iter(feed_dict):
        sys.stdout.write(feed_dict[title][0])

def convert(parsed_xml,options):#XXX
    if options.HTM:
        convert_html(parsed_xml)

    elif options.ADR:
        convert_adr(parsed_xml)

    elif options.TEXT:
        convert_text(parsed_xml)

    elif options.XBEL:
        convert_xbel(parsed_xml)

def handle_opts(Usage, Version):
    from optparse import OptionParser,OptionValueError

    oparser = OptionParser(usage=Usage,version=Version)
    
    oparser.add_option("-p","--pass",dest="PASS",#<- for use in scripts
                       action="store",type="str")

    oparser.add_option("-c","--count",dest="COUNT",
                       action="store",type="int",default=0,
                       help="""Number of bookmarks to retrieve
                                0 means all (default)""")

    oparser.add_option("-t","--text",dest="TEXT",
                       action="store_true",default=False,
                       help="Whether to use plain text")
    
    oparser.add_option("-a","--adr",dest="ADR",
                       action="store_true",default=False,
                       help="Whether to use Opera's ADR format")

    oparser.add_option("-n","--html",dest="HTM",
                       action="store_true",default=False,
                       help="Whether to use Netscape's HTML format")

    oparser.add_option("-x","--xbel",dest="XBEL",
                       action="store_true",default=True,
                       help="Whether to use the PXSIG's XBEL format (default)")


    return oparser.parse_args()

if __name__ == "__main__":
    usage = "usage: delectus USERNAME [options]"
    version = "0.6.2"
    (options, args) = handle_opts(usage,version)
    
    if len(args) < 1:
        sys.stderr.write("No username given - exiting\n")
        sys.stdout.write(usage + "\n")
        exit(1)
    else:
        username=args[0]
    if not options.PASS:
        import getpass
        password=getpass.getpass()

    url = api_url(username,password,options.COUNT)
    try:
        xml = get_xml(url)
    except UnboundLocalError:
        sys.stderr.write("Delicious returned an error\n")
        sys.stdout.write("Incorrect username or password?\n")
        sys.stdout.write(usage + "\n")
        exit(1)

    convert(parse_posts(xml),options)
    exit(0)

